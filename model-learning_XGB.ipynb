{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seaborn settings for visualizations!\n",
    "rc = {\n",
    "    \"axes.facecolor\": \"#f7f9fc\",\n",
    "    \"figure.facecolor\": \"#f7f9fc\",\n",
    "    \"axes.edgecolor\": \"#000000\",\n",
    "    \"grid.color\": \"#EBEBE7\",\n",
    "    \"font.family\": \"serif\",\n",
    "    \"axes.labelcolor\": \"#000000\",\n",
    "    \"xtick.color\": \"#000000\",\n",
    "    \"ytick.color\": \"#000000\",\n",
    "    \"grid.alpha\": 0.4\n",
    "}\n",
    "\n",
    "default_palette = 'YlOrRd'\n",
    "\n",
    "sns.set(rc=rc)\n",
    "pd.set_option('display.max_columns',35)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('/media/barry/DKCH/data/Thesis_data/20240410/rf-acls.csv')\n",
    "dataset_name = 'rf-acls'\n",
    "model_name = 'xgbc'\n",
    "original['recovery_class'] = pd.cut(original['recovery ratio'], bins=[-1, 0.5, 1.1], labels=[0, 1])\n",
    "original['recovery_class'].value_counts()\n",
    "#Let's check the Shape of data\n",
    "print(f'The Whole dataset has {original.shape[0]} rows and {original.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_types(dataframe):\n",
    "    continuous_vars = []\n",
    "    categorical_vars = []\n",
    "\n",
    "    for column in dataframe.columns:\n",
    "        if dataframe[column].dtype == 'object':\n",
    "            categorical_vars.append(column)\n",
    "        else:\n",
    "            continuous_vars.append(column)\n",
    "\n",
    "    return continuous_vars, categorical_vars\n",
    "\n",
    "continuous_vars, categorical_vars = get_variable_types(original)\n",
    "continuous_vars.remove('JOA')\n",
    "continuous_vars.remove('post JOA')\n",
    "continuous_vars.remove('recovery ratio')\n",
    "categorical_vars.remove('Case')\n",
    "categorical_vars.remove('whole cord at the max com level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_columns = []\n",
    "for columns_name in original.columns:\n",
    "    if 'Case' in columns_name:\n",
    "        del_columns.append(columns_name)\n",
    "    elif 'post JOA' in columns_name:\n",
    "        del_columns.append(columns_name)\n",
    "    elif 'recovery ratio' in columns_name:\n",
    "        del_columns.append(columns_name)\n",
    "    elif 'whole cord at the max com level' in columns_name:\n",
    "        del_columns.append(columns_name)\n",
    "print(del_columns)\n",
    "train = original.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=categorical_vars, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the Shape of data\n",
    "print(f'The encoded Train dataset has {train.shape[0]} rows and {train.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['recovery_class'], axis=1)\n",
    "y = train['recovery_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_original, X_test, y_train_original, y_test = train_test_split(X, y, test_size = 0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random oversampling\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "# define oversampling strategy\n",
    "ros = SMOTENC(random_state=42,categorical_features=[-1])\n",
    "# fit and apply the transform\n",
    "X_train, y_train = ros.fit_resample(X_train_original, y_train_original)\n",
    "print('bad:', y_train.value_counts()[0], '/', round(y_train.value_counts()[0]/len(y_train) * 100,2), '% of the dataset')\n",
    "print('good:', y_train.value_counts()[1], '/',round(y_train.value_counts()[1]/len(y_train) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "Hyperparameters for XGBClassifier using Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "     # Define parameters to be optimized for the LGBMClassifier\n",
    "     param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 15),\n",
    "        'subsample': trial.suggest_discrete_uniform('subsample', 0.6, 1.0, 0.05),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000, 10000, 100),\n",
    "        'eta': trial.suggest_discrete_uniform('eta', 0.01, 0.1, 0.01),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 1, 50),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 5, 100),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 20),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"random_state\":42\n",
    "    }\n",
    "\n",
    " # LGBMClassifier with the suggested parameters\n",
    "     lgbm_classifier = XGBClassifier(**param)\n",
    "    \n",
    "# Fit \n",
    "     lgbm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "     score = lgbm_classifier.score(X_test, y_test, )\n",
    "\n",
    "     return score\n",
    "\n",
    "# Train Test split\n",
    "X_train_original, X_test, y_train_original, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y) \n",
    "\n",
    "# random oversampling\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "# define oversampling strategy\n",
    "ros = SMOTENC(random_state=42,categorical_features=[-1])\n",
    "# fit and apply the transform\n",
    "X_train, y_train = ros.fit_resample(X_train_original, y_train_original)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#sampler for Optuna optimization\n",
    "sampler = optuna.samplers.TPESampler(seed=42)  # Using Tree-structured Parzen Estimator sampler for optimization\n",
    "\n",
    "# Create a study object\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "\n",
    "# Run the optimization process\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), n_trials=50)\n",
    "\n",
    "# best parameters after optimization\n",
    "best_params = study.best_params\n",
    "\n",
    "print('='*50)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_classifier = XGBClassifier(**best_params)\n",
    "lgbm_classifier.fit(X_train, y_train)\n",
    "y_pred = lgbm_classifier.predict(X_test)\n",
    "accuracy_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = lgbm_classifier.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df.to_csv(\"feature_importance_xgb.csv\")\n",
    "name_del = []\n",
    "for name_index,name in enumerate(X.columns):\n",
    "    if feature_importance[name_index]<=0:\n",
    "        name_del.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score,f1_score,recall_score, roc_curve, auc\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "best_params = study.best_params\n",
    "accuracy_train_multi = []\n",
    "accuracy_test_multi = []\n",
    "recall_train_multi = []\n",
    "recall_test_multi = []\n",
    "precision_train_multi = []\n",
    "precision_test_multi = []\n",
    "f1_score_train_multi = []\n",
    "f1_score_test_multi = []\n",
    "auc_test_multi = []\n",
    "fpr_test_multi = []\n",
    "tpr_test_multi = []\n",
    "\n",
    "accuracy_test_list = []\n",
    "recall_test_list = []\n",
    "precision_test_list = []\n",
    "f1_score_test_list = []\n",
    "auc_test_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)# \n",
    "\n",
    "    accuracy_train = []\n",
    "    accuracy_test = []\n",
    "    recall_train = []\n",
    "    recall_test = []\n",
    "    precision_train = []\n",
    "    precision_test = []\n",
    "    f1_score_train = []\n",
    "    f1_score_test = []\n",
    "    fpr_test = []\n",
    "    tpr_test = []\n",
    "    auc_test = []\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        y_train = le.fit_transform(y_train)\n",
    "        y_test = le.transform(y_test)\n",
    "        \n",
    "        \n",
    "        # define oversampling strategy\n",
    "        ros = SMOTENC(random_state=42,categorical_features=[-1])\n",
    "        # fit and apply the transform\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "        \n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        model = XGBClassifier(**best_params,random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        fpr, tpr, thersholds = roc_curve(y_test, y_test_pred, pos_label=1)\n",
    "        linear_interpolator = interpolate.interp1d(fpr, tpr, kind='linear')\n",
    "        fpr_new = np.linspace(0, 1, 100)\n",
    "        tpr_new = linear_interpolator(fpr_new)\n",
    "        roc_auc = auc(fpr_new, tpr_new)\n",
    "        tpr_test.append(tpr_new)\n",
    "        auc_test.append(roc_auc)\n",
    "        \n",
    "        accuracy_train.append(accuracy_score(y_train, y_train_pred))\n",
    "        accuracy_test.append(accuracy_score(y_test, y_test_pred))\n",
    "        recall_train.append(recall_score(y_train, y_train_pred))\n",
    "        recall_test.append(recall_score(y_test, y_test_pred))\n",
    "        precision_train.append(precision_score(y_train, y_train_pred))\n",
    "        precision_test.append(precision_score(y_test, y_test_pred))\n",
    "        f1_score_train.append(f1_score(y_train, y_train_pred))\n",
    "        f1_score_test.append(f1_score(y_test, y_test_pred))\n",
    "        \n",
    "        # print('------Weighted------')\n",
    "        # print('Weighted precision', precision_score(y_test, y_test_pred, average='weighted'))\n",
    "        # print('Weighted recall', recall_score(y_test, y_test_pred, average='weighted'))\n",
    "        # print('Weighted f1-score', f1_score(y_test, y_test_pred, average='weighted'))\n",
    "        # print('------Macro------')\n",
    "        # print('Macro precision', precision_score(y_test, y_test_pred, average='macro'))\n",
    "        # print('Macro recall', recall_score(y_test, y_test_pred, average='macro'))\n",
    "        # print('Macro f1-score', f1_score(y_test, y_test_pred, average='macro'))\n",
    "        # print('------Micro------')\n",
    "        # print('Micro precision', precision_score(y_test, y_test_pred, average='micro'))\n",
    "        # print('Micro recall', recall_score(y_test, y_test_pred, average='micro'))\n",
    "        # print('Micro f1-score', f1_score(y_test, y_test_pred, average='micro'))\n",
    "    acc_train = np.array(accuracy_train)\n",
    "    acc_test = np.array(accuracy_test)\n",
    "    rec_train = np.array(recall_train)\n",
    "    rec_test = np.array(recall_test)\n",
    "    pre_train = np.array(precision_train)\n",
    "    pre_test = np.array(precision_test)\n",
    "    f1_train = np.array(f1_score_train)\n",
    "    f1_test = np.array(f1_score_test)\n",
    "    auc_test = np.array(auc_test)\n",
    "    tpr_test = np.array(tpr_test).mean(0).T\n",
    "\n",
    "    accuracy_train_multi.append(acc_train.mean())\n",
    "    accuracy_test_multi.append(acc_test.mean())\n",
    "    recall_train_multi.append(rec_train.mean())\n",
    "    recall_test_multi.append(rec_test.mean())\n",
    "    precision_train_multi.append(pre_train.mean())\n",
    "    precision_test_multi.append(pre_test.mean())\n",
    "    f1_score_train_multi.append(f1_train.mean())\n",
    "    f1_score_test_multi.append(f1_test.mean())\n",
    "    auc_test_multi.append(auc_test.mean())\n",
    "    tpr_test_multi.append(tpr_test.T)\n",
    "    \n",
    "    accuracy_test_list.append(acc_test)\n",
    "    recall_test_list.append(rec_test)\n",
    "    precision_test_list.append(pre_test)\n",
    "    f1_score_test_list.append(f1_test)\n",
    "    auc_test_list.append(auc_test)\n",
    "\n",
    "print(\"mean accuracy is: {:.4f} $\\pm$ {:.2f}\".format(np.array(accuracy_test_multi).mean(),np.array(accuracy_test_multi).std()))\n",
    "print(\"mean recall is: {:.4f} $\\pm$ {:.2f}\".format(np.array(recall_test_multi).mean(),np.array(recall_test_multi).std()))\n",
    "print(\"mean precision is: {:.4f} $\\pm$ {:.2f}\".format(np.array(precision_test_multi).mean(),np.array(precision_test_multi).std()))\n",
    "print(\"mean f1 is: {:.4f} $\\pm$ {:.2f}\".format(np.array(f1_score_test_multi).mean(),np.array(f1_score_test_multi).std()))\n",
    "print(\"mean auc is: {:.4f} $\\pm$ {:.2f}\".format(np.array(auc_test_multi).mean(),np.array(auc_test_multi).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(accuracy_test_list).to_csv('accuracy.csv')\n",
    "pd.DataFrame(recall_test_list).to_csv('recall.csv')\n",
    "pd.DataFrame(precision_test_list).to_csv('precision.csv')\n",
    "pd.DataFrame(f1_score_test_list).to_csv('f1-score.csv')\n",
    "pd.DataFrame(auc_test_list).to_csv('auc.csv')\n",
    "pd.DataFrame(tpr_test_multi).to_csv('tpr.csv')\n",
    "pd.DataFrame(fpr_new).to_csv('fpr.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal_use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
